{smcl}
{* 25jan2007}{...}
{hline}
help for {hi:mvrs}{right:(SJ7-1: st0120)}
{hline}

{title:Multivariable regression spline models}

{p 8 12 2}
{cmd:mvrs}
{it:regression_cmd}
[{it:yvar}]
{it:xvarlist}
{ifin}
{weight}
[{cmd:,}
{cmd:all}
{cmdab:al:pha}{cmd:(}{it:alpha_list}{cmd:)}
{cmdab:cyc:les}{cmd:(}{it:#}{cmd:)}
{cmdab:deg:ree}{cmd:(}{it:#}{cmd:)}
{cmd:df(}{it:df_list}{cmd:)}
{cmdab:dfd:efault}{cmd:(}{it:#}{cmd:)}
{cmdab:kn:ots}{cmd:(}{it:knot_list}{cmd:)}
{cmdab:sel:ect}{cmd:(}{it:select_list}{cmd:)}
{cmdab:xo:rder}{cmd:(}{cmd:+}|{cmd:-}|{cmd:n}{cmd:)}
{it:regression_cmd_options}
]


{p 4 4 2}
where

{p 8 8 2}
{it:regression_cmd} may be
{helpb clogit},
{helpb glm},
{helpb logistic},
{helpb logit},
{helpb ologit},
{helpb oprobit},
{helpb poisson},
{helpb probit},
{helpb qreg},
{helpb regress},
{helpb stcox},
{helpb streg},
or
{helpb xtgee}.

{p 8 8 2}
{it:xvarlist} has elements of type {it:varlist} and/or
{cmd:(}{it:varlist}{cmd:)}, e.g.,

{p 12 12 2}
{cmd:x1 x2 (x3 x4 x5)}

{p 8 8 2}
{it:yvar} is required with all {it:regression_cmd}s except
{cmd:stcox} and {cmd:streg}.  For the last two commands, {it:yvar} is not
allowed, and you must have {helpb stset} your data first.

{p 4 4 2}
{cmd:mvrs}
shares the features of all estimation commands; see {help estcom}.

{p 4 4 2}
{helpb fracplot} may be used after {cmd:mvrs} to show plots of fitted values
and partial residuals. {helpb fracpred} may be used for prediction.

{p 4 4 2}
All weight types supported by {it:regression_cmd} are allowed; see help
{help weights}.


{title:Description}

{p 4 4 2}
{cmd:mvrs} selects the regression spline (RS) model that best predicts the
outcome variable {it:yvar} from the right-hand-side variables in {it:xvarlist}.


{title:Options}

{p 4 8 2}
{cmd:all} includes out-of-sample observations when generating the spline
transformations of predictors. By default, the generated variables contain
missing values outside the estimation sample.

{p 4 8 2}
{cmd:alpha(}{it:alpha_list}{cmd:)}
    sets the significance levels for testing between RS models
    of different complexity (numbers of knots).
    The rules for {it:alpha_list} are the same as for
    {it:df_list} in the {helpb mvrs##df:df()} option.
    The default nominal p-value (significance level, selection level) is 0.05
    for all variables.

{p 8 8 2}
    {cmd:alpha(0.01)} specifies that all variables have RS selection level 1%.
    {cmd:alpha(0.05, weight:0.1)} specifies that all variables except
    {cmd:weight} have RS selection level 5%; {cmd:weight} has level 10%.

{p 4 8 2}
{cmd:cycles(}{it:#}{cmd:)} is the maximum number of iteration cycles
    permitted.  The default is {cmd:cycles(5)}.

{p 4 8 2}
{cmd:degree(}{it:#}{cmd:)} determines the type of spline transformation
    to be used. Valid values of {it:#} are 0, 1, and 3. The value of 0
    denotes a step function, whereas 1 and 3 denote linear and cubic splines,
    respectively. The cubic splines are natural; that is, the curves are
    restricted to be linear beyond the observed range of the predictor in
    question.  The default is {cmd:degree(3)}, meaning a natural cubic spline.

{marker df}{...}
{p 4 8 2}
{cmd:df(}{it:df_list}{cmd:)}
    sets up the degrees of freedom (df) for each predictor. For splines
    of degree 1 and 3, the df (not counting the regression constant,
    {cmd:_cons}) are equal to the number of knots plus 1. For splines
    of degree 0 (i.e., step functions), the df are equal to the number
    of knots. Specifying {cmd:df(1)} forces linear functions (no knots)
    for splines of degree 1 or 3 but forces dichotomization at the
    median for splines of degree 0.
    The first item in {it:df_list} may be either {it:#} or
    {it:varlist}{cmd::}{it:#}.  Later items must be
    {it:varlist}{cmd::}{it:#}.  Items are separated by commas and {it:varlist}
    is specified in the usual way for variables.  With the first type of item,
    the df for all predictors are taken to be {it:#}.  With the second type of
    item, all members of {it:varlist} (which must be a subset of
    {it:xvarlist}) have {it:#} df.

{p 8 8 2}
    The default df for a predictor of type {it:varlist} specified in
    {it:xvarlist} but not in {it:df_list} are assigned according to the
     number of distinct (unique) values of the predictor, as follows:

        {hline 43}
        No. of distinct values    Default df
        {hline 43}
        {ul:<}1                       (invalid predictor)
        2-3                      1
        4-5                      min(2, {cmd:dfdefault()})
        {ul:>}6                       {cmd:dfdefault()}
        {hline 43}

{p 8 8 2}
    {cmd:df(4)} means that all variables have 4 df. {cmd:df(2, weight displ:4)}
    means that {cmd:weight} and {cmd:displ} have 4 df, and all other variables
    have 2 df.  {cmd:df(weight displ:4, mpg:2)} means that 
    {cmd:weight} and {cmd:displ} have 4 df, {cmd:mpg} has 2 df, and all other
    variables have the default of 1 df.  {cmd:df(weight displ:4, 2)} is an
    invalid combination:  the final 2 would override the earlier 4.

{p 4 8 2}
{cmd:dfdefault(}{it:#}{cmd:)} determines the default maximum df for a
   predictor. The default is {cmd:dfdefault(4)} (three knots for degree 1 or
   3, four knots for degree 0).
 
{p 4 8 2} {cmd:knots}{cmd:(}{it:knot_list}{cmd:)} sets knots for predictors 
   individually.  The syntax of {it:knot_list} is the same as for {it:df_list}
   in the {cmd:df()} option. By default, knots are placed at equally spaced
   centiles of the distribution of the predictor {it:x} in question. For
   example, by default three knots are placed at the 25th, 50th, and 75th
   centiles of any continuous {it:x}. The {cmd:knots()} option can be used to
   override this choice.

{p 8 8 2}
    {cmd:knots(1 3 5)} means that all variables have knots at 1, 3, and 5
    (unlikely to be sensible).  {cmd:knots(x5:1 3 5)} means that 
    all variables except {cmd:x5} have default knots; {cmd:x5} has knots at 1,
    3, and 5.

{p 4 8 2}
{cmd:select(}{it:select_list}{cmd:)}
    sets the nominal p-values (significance levels) for variable selection by
    backward elimination.  A variable is dropped if its removal causes a
    nonsignificant increase in deviance.  The rules for {it:select_list} are
    the same as for {it:df_list} in the {cmd:df()} option (see above).  Using
    the default {cmd:select(1)} for all variables forces them all into
    the model.  The nominal p-value for elements {cmd:(}{it:varlist}{cmd:)}
    of {it:xvarlist} is specified
    by including {cmd:(}{it:varlist}{cmd:)} in {it:select_list}.
    See also the {cmd:alpha()} option and {it:Remarks}). The nominal p-value
    for elements {it:varlist} of {it:xvarlist} bound by parentheses is
    specified by including {cmd:(}{it:varlist}{cmd:)} in {it:select_list}.

{p 8 8 2}
    {cmd:select(0.05)} means that all variables have nominal p-value 5%.
    {cmd:select(0.05, weight:1)} means that all variables except {cmd:weight}
    have nominal p-value 5%; {cmd:weight} is forced into the model.

{p 4 8 2}
{cmd:xorder}{cmd:(}{cmd:+}|{cmd:-}|{cmd:n}{cmd:)}
    determines the order of entry of the predictors into the model selection
    algorithm. The default is {cmd:xorder(+)}, which enters them in decreasing
    order of significance in a multiple linear regression (most significant
    first). {cmd:xorder(-)} places them in reverse significance order, whereas
    {cmd:xorder(n)} respects the original order in {it:xvarlist}.

{p 4 8 2}
{it:regression_cmd_options} may be any of the options appropriate to
    {it:regression_cmd}.


{title:Remarks}

{p 4 4 2}
For elements in {it:xvarlist}, {cmd:mvrs} leaves
variables in the data named {it:xvar}{cmd:_1},
{it:xvar}{cmd:_2}, ..., where {it:xvar} represents the
letters of the name of {it:xvar1}, and so on for {it:xvar2}, {it:xvar3}, etc.
The new variables contain the spline basis variables for the best-fitting
spline model for {it:xvar1}, {it:xvar2}, ....

    {title:Iteration report}

{p 4 4 2}
By default, for each continuous predictor, X, {cmd:mvrs} compares null, linear
and lower-dimensional spline models for X with the most complex spline model
allowed by the specification ({cmd:df()} and {cmd:dfdefault()} options).
The deviance for each of these nested submodels is given in the column
headed "Deviance". The column labeled "Final knots" shows the knots
selected as best-fitting subject to the testing procedure.
All the other predictors currently selected are included, with
their transformations (if any).  For models specified as having 1 df,
the only choice is whether the variable enters the model.

    {title:Estimation algorithm}

{p 4 4 2}
The model-selection algorithm has the flavor of a closed-test procedure.
The {it:xvars} are processed in turn.
Initially, {cmd:mvrs} silently arranges {it:xvarlist} in order of increasing
p-value (i.e., of decreasing statistical significance) for omitting each
predictor from the model comprising {it:xvarlist} with each term linear.  The
aim is to model relatively important variables before unimportant ones.  This
may help to reduce potential model-fitting difficulties caused by collinearity
or, more generally, "concurvity" among the predictors.  (See the
{cmd:xorder()} option above for details of how to change the ordering.)

{p 4 4 2}
At the initial cycle, the best-fitting RS function for {it:xvar1} (the first
of {it:xvarlist}) is determined, with all the other variables assumed linear.
For details of the procedure, see
{it:{help mvrs##methodrs:Method of RS model selection}}).
The functional form (but not the estimated
regression coefficients) for {it:xvar1} is kept, and the process is repeated
for {it:xvar2}, {it:xvar3}, etc.  The first iteration concludes when all the
variables have been processed in this way.  The next cycle is similar, except
that the functional forms from the initial cycle are retained for all
variables except the one currently being processed.

{p 4 4 2}
A variable whose functional form is prespecified to be linear (i.e., to have 1
df) is tested only for exclusion within the above procedure when its nominal
p-value (selection level) according to {cmd:select()} is less than 1.

{p 4 4 2}
Updating of RS functions and candidate variables continues until the functions
and variables included in the overall model do not change (convergence).
Convergence is usually achieved within one to four cycles.

{marker methodrs}{...}
    {title:Method of RS model selection}

{p 4 4 2}
The model-selection algorithm in {cmd:mvrs} embodies a type of backward
elimination with the flavor of a closed-test procedure. The latter is a
sequence of tests maintaining the overall type I error rate at a prespecified
nominal level, such as 5%. The algorithm starts from the most complex permitted
RS model and attempts to simplify the model by removing spline terms according
to their statistical significance.

{p 4 4 2}
The closed-test procedure for choosing an RS model with maximum
permitted df determined by {cmd:df()}, 
for a single-continuous predictor, {it:x},
is described in the {it:Remarks} section of {helpb uvrs}.


{title:Examples}

{p 4 16 2}
{cmd:. mvrs regress mpg weight displacement foreign}

{p 4 16 2}
{cmd:. mvrs regress mpg weight displacement foreign, df(1, displacement:4)}

{p 4 16 2}
{cmd:. mvrs regress mpg weight displacement foreign, df(2, foreign:1)}
{cmd:degree(1) select(0.05, foreign:1)}

{p 4 16 2}
{cmd:. xi: mvrs regress mpg weight displacement foreign (i.rep78), dfdefault(2)}
{cmd:select(0.05, foreign (i.rep78):1)}

{p 4 16 2}
{cmd:. xi: mvrs regress mpg weight displacement foreign i.rep78, dfdefault(2)}
{cmd:degree(0)}

{p 4 16 2}
{cmd:. fracplot weight}


{title:Author}

{p 4 4 2}
Patrick Royston, MRC Clinical Trials Unit, London{break}
patrick.royston@ctu.mrc.ac.uk


{title:Also see}

{p 4 13 2}
Manual:  {hi:[R] mfp}

{p 4 13 2}
Online:  {help estcom}, {help postest}; {helpb uvrs};
{helpb splinegen}; {helpb fracpoly}; {helpb mfp}
{p_end}
